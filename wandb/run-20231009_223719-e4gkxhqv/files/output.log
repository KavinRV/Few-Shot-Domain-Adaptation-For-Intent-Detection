
Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 578/578 [00:00<00:00, 2.18MB/s]
Downloading data files:   0%|                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]





Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:24<00:00, 24.01s/it]
Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1169.31it/s]

Generating train split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138200/138200 [00:00<00:00, 254082.69 examples/s]
Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 553/553 [00:00<00:00, 1.85MB/s]
Downloading data files:   0%|                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.69s/it]
Extracting data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 535.88it/s]
Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22390/22390 [00:00<00:00, 100392.83 examples/s]
/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:199: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(





























  3%|█████▏                                                                                                                                                                                    | 30/1075 [04:33<2:37:35,  9.05s/it]
  1%|█                                                                                                                                                                                            | 6/1120 [00:01<03:15,  5.71it/s]







  File "/raid/kavin-intern-maunendra/GenRet/rankt5_da.py", line 222, in <module>                                                                                                                 | 92/1120 [00:16<03:22,  5.08it/s]
    trainer.save_model(f"{model_dir}/final")
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 1901, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 2226, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 159, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 2934, in evaluate
    output = eval_loop(
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 3123, in evaluation_loop
    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 250, in prediction_step
    return super().prediction_step(
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 3337, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/transformers/trainer.py", line 2679, in compute_loss
    outputs = model(**inputs)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/kavin-intern-maunendra/GenRet/rankt5_da.py", line 78, in forward
    wandb.log({"loss": loss})
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 419, in wrapper
    return func(self, *args, **kwargs)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 370, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 360, in wrapper
    return func(self, *args, **kwargs)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 1792, in log
    self._log(data=data, step=step, commit=commit)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 1567, in _log
    self._partial_history_callback(data, step, commit)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/wandb_run.py", line 1439, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/sdk/interface/interface.py", line 540, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/util.py", line 839, in json_dumps_safer_history
    return dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/util.py", line 800, in default
    obj, converted = json_friendly(obj)
  File "/raid/kavin-intern-maunendra/anaconda3/envs/wow/lib/python3.10/site-packages/wandb/util.py", line 612, in json_friendly
    return obj.item(), True
KeyboardInterrupt